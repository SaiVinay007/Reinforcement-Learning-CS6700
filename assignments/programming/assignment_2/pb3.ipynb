{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import gym\n",
    "import gym_pdw\n",
    "\n",
    "import numpy as np\n",
    "from matplotlib import pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "env = gym.make('gym_pdw:pdw-v0')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def SARSA_lambda(gamma, alpha, epsilon, episodes, lambda_val):\n",
    "    \n",
    "    # Set the goal variant\n",
    "    goal_pos = env.set_goal('A')\n",
    "\n",
    "    # Setting terminal action-state value \n",
    "    Terminal_state = goal_pos\n",
    "\n",
    "    # Initializing Q function values to zero\n",
    "    Q = np.zeros([env.observation_space.shape[0], env.observation_space.shape[1], env.action_space.n])\n",
    "\n",
    "    \n",
    "    # Epsilon-greedy action selection\n",
    "    def select_action(epsilon, state):\n",
    "        if np.random.uniform(0,1) < epsilon:\n",
    "            action = env.random_action()\n",
    "        else:\n",
    "            action = np.argmax(Q[state[0],state[1]][:])\n",
    "        return action\n",
    "\n",
    "    \n",
    "    # Q function update \n",
    "    def update(state, action, reward, next_state, next_action, E):\n",
    "        nonlocal Q\n",
    "        error = reward + gamma*Q[next_state[0],next_state[1]][next_action] - Q[state[0],state[1]][action]\n",
    "        Q = Q + alpha*error*E\n",
    "\n",
    "        \n",
    "    steps = np.zeros([episodes])\n",
    "    avg_reward = np.zeros([episodes])\n",
    "    \n",
    "    for episode in range(episodes):\n",
    "\n",
    "        env.reset()\n",
    "        \n",
    "        curr_state = env.get_state()\n",
    "        action = env.random_action()\n",
    "        \n",
    "        print(curr_state ,\"init====================\")\n",
    "\n",
    "        E = np.zeros([12,12,4])\n",
    "\n",
    "        while True:\n",
    "            \n",
    "            if steps[episode] != 0:\n",
    "                action = select_action(epsilon, curr_state)\n",
    "            \n",
    "            next_state, reward = env.step(action)\n",
    "            next_action = select_action(epsilon, next_state)\n",
    "\n",
    "            # Update eligibility traces\n",
    "            E *= gamma*lambda_val\n",
    "            E[curr_state[0],curr_state[1]][action] += 1\n",
    "            \n",
    "            # Update Q values\n",
    "            update(curr_state, action, reward, next_state, next_action, E)\n",
    "            \n",
    "            \n",
    "            steps[episode] +=1\n",
    "            avg_reward[episode] = avg_reward[episode] + (reward - avg_reward[episode])/steps[episode]\n",
    "            \n",
    "            \n",
    "            curr_state = next_state\n",
    "            print(curr_state, \"curr_state\", env.start_positions)\n",
    "\n",
    "            if curr_state == goal_pos:\n",
    "                print(\"yes\", steps[episode])\n",
    "                break\n",
    "    \n",
    "    return avg_reward, steps, Q"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_sarsa_lambda(avg_reward, steps, episodes):\n",
    "    '''\n",
    "    Gets the data for all curves and plots them in one graph\n",
    "    '''\n",
    "\n",
    "    \n",
    "    # Figure instances will be returned.\n",
    "    fig1=plt.figure(figsize=(10,6)).add_subplot(111)\n",
    "    fig2=plt.figure(figsize=(10,6)).add_subplot(111)\n",
    "\n",
    "    # colors for different values of epsilon\n",
    "    colors = ['g', 'r', 'k', 'b', 'y','m', 'c']\n",
    "\n",
    "    fig1.plot(range(episodes), avg_reward, colors[0], label = \" Average reward \" )\n",
    "    fig2.plot(range(episodes), steps, colors[1], label = \" Steps\")\n",
    "\n",
    "    # Labelling the plot\n",
    "    fig1.title.set_text('SARSA avg reward')\n",
    "    fig1.set_ylabel('Average Reward')\n",
    "    fig1.set_xlabel('episodes')\n",
    "    fig1.legend(bbox_to_anchor=(1.05, 1), loc=2, borderaxespad=0.)\n",
    "\n",
    "    # Labelling the plot\n",
    "    fig2.title.set_text('SARSA num steps')\n",
    "    fig2.set_ylabel('Steps')\n",
    "    fig2.set_xlabel('episodes')\n",
    "    fig2.legend(bbox_to_anchor=(1.05, 1), loc=2, borderaxespad=0.)\n",
    "\n",
    "    # Display the plot\n",
    "#     plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_compare(avg_reward_all, steps_all, lambda_vals):\n",
    "    \n",
    "    # Figure instances will be returned.\n",
    "    fig1=plt.figure(figsize=(10,6)).add_subplot(111)\n",
    "    fig2=plt.figure(figsize=(10,6)).add_subplot(111)\n",
    "\n",
    "    # colors for different values of c\n",
    "    colors = ['k', 'r', 'g', 'm', 'y','k', 'c']\n",
    "\n",
    "    # For each value of c, plot the average reward vs steps\n",
    "    for i in range(len(avg_reward_all)):\n",
    "        fig1.plot(range(episodes), steps_all[i], colors[i], label = \"lambda = \" + str(lambda_vals[i]) )\n",
    "    \n",
    "    # For each c, plot the % times optimal arm selected vs steps\n",
    "    for i in range(len(steps_all)):\n",
    "        fig2.plot(range(episodes), steps_all[i], colors[i], label = \"lambda = \" + str(lambda_vals[i]) )\n",
    "    \n",
    "    # Labelling the  plot\n",
    "    fig1.title.set_text('For all lambdas Average reward vs episodes')\n",
    "    fig1.set_ylabel('Average Reward')\n",
    "    fig1.set_xlabel('episodes')\n",
    "    fig1.legend(bbox_to_anchor=(1.05, 1), loc=2, borderaxespad=0.)\n",
    "    \n",
    "    # Labelling the plot\n",
    "    fig2.title.set_text('For all lambdas steps vs episodes')\n",
    "    fig2.set_ylabel('Steps')\n",
    "    fig2.set_xlabel('episodes')\n",
    "    fig2.legend(bbox_to_anchor=(1.05, 1), loc=2, borderaxespad=0.)\n",
    "\n",
    "    # Display the plot\n",
    "    plt.show()\n",
    "\n"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "if __name__=='__main__':\n",
    "    # parameters\n",
    "    gamma = 0.9\n",
    "    alpha = 0.01\n",
    "    epsilon = 0.1\n",
    "    episodes = 50\n",
    "    \n",
    "    lambda_vals = [0, 0.3, 0.5, 0.9, 0.99, 1.0]\n",
    "    \n",
    "    avg_reward_all = []\n",
    "    steps_all = []\n",
    "    \n",
    "    for i in range(len(lambda_vals)):\n",
    "        avg_reward, steps, Q = SARSA_lambda(gamma,alpha,epsilon, episodes, lambda_vals[i])\n",
    "        \n",
    "        avg_reward_all.append(avg_reward)\n",
    "        steps_all.append(steps)\n",
    "        \n",
    "        plot_sarsa_lambda(avg_reward_all[i], steps_all[i], episodes)\n",
    "    plt.show\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[[0.7, 0.7, 0.7, 0.7],\n",
       "        [0.7, 0.7, 0.7, 0.7],\n",
       "        [0.7, 0.7, 0.7, 0.7],\n",
       "        [0.7, 0.7, 0.7, 0.7],\n",
       "        [0.7, 0.7, 0.7, 0.7],\n",
       "        [0.7, 0.7, 0.7, 0.7],\n",
       "        [0.7, 0.7, 0.7, 0.7],\n",
       "        [0.7, 0.7, 0.7, 0.7],\n",
       "        [0.7, 0.7, 0.7, 0.7],\n",
       "        [0.7, 0.7, 0.7, 0.7],\n",
       "        [0.7, 0.7, 0.7, 0.7],\n",
       "        [0.7, 0.7, 0.7, 0.7]],\n",
       "\n",
       "       [[0.7, 0.7, 0.7, 0.7],\n",
       "        [0.7, 0.7, 0.7, 0.7],\n",
       "        [0.7, 0.7, 0.7, 0.7],\n",
       "        [0.7, 0.7, 0.7, 0.7],\n",
       "        [0.7, 0.7, 0.7, 0.7],\n",
       "        [0.7, 0.7, 0.7, 0.7],\n",
       "        [0.7, 0.7, 0.7, 0.7],\n",
       "        [0.7, 0.7, 0.7, 0.7],\n",
       "        [0.7, 0.7, 0.7, 0.7],\n",
       "        [0.7, 0.7, 0.7, 0.7],\n",
       "        [0.7, 0.7, 0.7, 0.7],\n",
       "        [0.7, 0.7, 0.7, 0.7]],\n",
       "\n",
       "       [[0.7, 0.7, 0.7, 0.7],\n",
       "        [0.7, 0.7, 0.7, 0.7],\n",
       "        [0.7, 0.7, 0.7, 0.7],\n",
       "        [0.7, 0.7, 0.7, 1.7],\n",
       "        [0.7, 0.7, 0.7, 0.7],\n",
       "        [0.7, 0.7, 0.7, 0.7],\n",
       "        [0.7, 0.7, 0.7, 0.7],\n",
       "        [0.7, 0.7, 0.7, 0.7],\n",
       "        [0.7, 0.7, 0.7, 0.7],\n",
       "        [0.7, 0.7, 0.7, 0.7],\n",
       "        [0.7, 0.7, 0.7, 0.7],\n",
       "        [0.7, 0.7, 0.7, 0.7]],\n",
       "\n",
       "       [[0.7, 0.7, 0.7, 0.7],\n",
       "        [0.7, 0.7, 0.7, 0.7],\n",
       "        [0.7, 0.7, 0.7, 0.7],\n",
       "        [0.7, 0.7, 0.7, 0.7],\n",
       "        [0.7, 0.7, 0.7, 0.7],\n",
       "        [0.7, 0.7, 0.7, 0.7],\n",
       "        [0.7, 0.7, 0.7, 0.7],\n",
       "        [0.7, 0.7, 0.7, 0.7],\n",
       "        [0.7, 0.7, 0.7, 0.7],\n",
       "        [0.7, 0.7, 0.7, 0.7],\n",
       "        [0.7, 0.7, 0.7, 0.7],\n",
       "        [0.7, 0.7, 0.7, 0.7]],\n",
       "\n",
       "       [[0.7, 0.7, 0.7, 0.7],\n",
       "        [0.7, 0.7, 0.7, 0.7],\n",
       "        [0.7, 0.7, 0.7, 0.7],\n",
       "        [0.7, 0.7, 0.7, 0.7],\n",
       "        [0.7, 0.7, 0.7, 0.7],\n",
       "        [0.7, 0.7, 0.7, 0.7],\n",
       "        [0.7, 0.7, 0.7, 0.7],\n",
       "        [0.7, 0.7, 0.7, 0.7],\n",
       "        [0.7, 0.7, 0.7, 0.7],\n",
       "        [0.7, 0.7, 0.7, 0.7],\n",
       "        [0.7, 0.7, 0.7, 0.7],\n",
       "        [0.7, 0.7, 0.7, 0.7]],\n",
       "\n",
       "       [[0.7, 0.7, 0.7, 0.7],\n",
       "        [0.7, 0.7, 0.7, 0.7],\n",
       "        [0.7, 0.7, 0.7, 0.7],\n",
       "        [0.7, 0.7, 0.7, 0.7],\n",
       "        [0.7, 0.7, 0.7, 0.7],\n",
       "        [0.7, 0.7, 0.7, 0.7],\n",
       "        [0.7, 0.7, 0.7, 0.7],\n",
       "        [0.7, 0.7, 0.7, 0.7],\n",
       "        [0.7, 0.7, 0.7, 0.7],\n",
       "        [0.7, 0.7, 0.7, 0.7],\n",
       "        [0.7, 0.7, 0.7, 0.7],\n",
       "        [0.7, 0.7, 0.7, 0.7]],\n",
       "\n",
       "       [[0.7, 0.7, 0.7, 0.7],\n",
       "        [0.7, 0.7, 0.7, 0.7],\n",
       "        [0.7, 0.7, 0.7, 0.7],\n",
       "        [0.7, 0.7, 0.7, 0.7],\n",
       "        [0.7, 0.7, 0.7, 0.7],\n",
       "        [0.7, 0.7, 0.7, 0.7],\n",
       "        [0.7, 0.7, 0.7, 0.7],\n",
       "        [0.7, 0.7, 0.7, 0.7],\n",
       "        [0.7, 0.7, 0.7, 0.7],\n",
       "        [0.7, 0.7, 0.7, 0.7],\n",
       "        [0.7, 0.7, 0.7, 0.7],\n",
       "        [0.7, 0.7, 0.7, 0.7]],\n",
       "\n",
       "       [[0.7, 0.7, 0.7, 0.7],\n",
       "        [0.7, 0.7, 0.7, 0.7],\n",
       "        [0.7, 0.7, 0.7, 0.7],\n",
       "        [0.7, 0.7, 0.7, 0.7],\n",
       "        [0.7, 0.7, 0.7, 0.7],\n",
       "        [0.7, 0.7, 0.7, 0.7],\n",
       "        [0.7, 0.7, 0.7, 0.7],\n",
       "        [0.7, 0.7, 0.7, 0.7],\n",
       "        [0.7, 0.7, 0.7, 0.7],\n",
       "        [0.7, 0.7, 0.7, 0.7],\n",
       "        [0.7, 0.7, 0.7, 0.7],\n",
       "        [0.7, 0.7, 0.7, 0.7]],\n",
       "\n",
       "       [[0.7, 0.7, 0.7, 0.7],\n",
       "        [0.7, 0.7, 0.7, 0.7],\n",
       "        [0.7, 0.7, 0.7, 0.7],\n",
       "        [0.7, 0.7, 0.7, 0.7],\n",
       "        [0.7, 0.7, 0.7, 0.7],\n",
       "        [0.7, 0.7, 0.7, 0.7],\n",
       "        [0.7, 0.7, 0.7, 0.7],\n",
       "        [0.7, 0.7, 0.7, 0.7],\n",
       "        [0.7, 0.7, 0.7, 0.7],\n",
       "        [0.7, 0.7, 0.7, 0.7],\n",
       "        [0.7, 0.7, 0.7, 0.7],\n",
       "        [0.7, 0.7, 0.7, 0.7]],\n",
       "\n",
       "       [[0.7, 0.7, 0.7, 0.7],\n",
       "        [0.7, 0.7, 0.7, 0.7],\n",
       "        [0.7, 0.7, 0.7, 0.7],\n",
       "        [0.7, 0.7, 0.7, 0.7],\n",
       "        [0.7, 0.7, 0.7, 0.7],\n",
       "        [0.7, 0.7, 0.7, 0.7],\n",
       "        [0.7, 0.7, 0.7, 0.7],\n",
       "        [0.7, 0.7, 0.7, 0.7],\n",
       "        [0.7, 0.7, 0.7, 0.7],\n",
       "        [0.7, 0.7, 0.7, 0.7],\n",
       "        [0.7, 0.7, 0.7, 0.7],\n",
       "        [0.7, 0.7, 0.7, 0.7]],\n",
       "\n",
       "       [[0.7, 0.7, 0.7, 0.7],\n",
       "        [0.7, 0.7, 0.7, 0.7],\n",
       "        [0.7, 0.7, 0.7, 0.7],\n",
       "        [0.7, 0.7, 0.7, 0.7],\n",
       "        [0.7, 0.7, 0.7, 0.7],\n",
       "        [0.7, 0.7, 0.7, 0.7],\n",
       "        [0.7, 0.7, 0.7, 0.7],\n",
       "        [0.7, 0.7, 0.7, 0.7],\n",
       "        [0.7, 0.7, 0.7, 0.7],\n",
       "        [0.7, 0.7, 0.7, 0.7],\n",
       "        [0.7, 0.7, 0.7, 0.7],\n",
       "        [0.7, 0.7, 0.7, 0.7]],\n",
       "\n",
       "       [[0.7, 0.7, 0.7, 0.7],\n",
       "        [0.7, 0.7, 0.7, 0.7],\n",
       "        [0.7, 0.7, 0.7, 0.7],\n",
       "        [0.7, 0.7, 0.7, 0.7],\n",
       "        [0.7, 0.7, 0.7, 0.7],\n",
       "        [0.7, 0.7, 0.7, 0.7],\n",
       "        [0.7, 0.7, 0.7, 0.7],\n",
       "        [0.7, 0.7, 0.7, 0.7],\n",
       "        [0.7, 0.7, 0.7, 0.7],\n",
       "        [0.7, 0.7, 0.7, 0.7],\n",
       "        [0.7, 0.7, 0.7, 0.7],\n",
       "        [0.7, 0.7, 0.7, 0.7]]])"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "E = np.ones([12,12,4])\n",
    "E *= 0.7\n",
    "E[2,3][3] += 1\n",
    "E"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
